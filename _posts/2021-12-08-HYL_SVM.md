---
layout: post
title: "Notes for Prof. Hung-Yi Lee's ML Lecture: Support Vector Machine"
---

## My Intuitive Explanation

The steps of using SVM is:

the overall computation is equivalent to:
1. transform the features to a high-dimensional (often infinite-dimensional) space.
2. find a plane to separate the 2 classes by the hinge loss.
3. use the plane to classify new data.

1. By the kernel method, when classifying new data, we calculate the kernel function betwen the new data and all the training data in the original space, so we don't have to perform computations in the high-dimensional space.
2. By the kernal method and the hinge loss, we only have to calculate the kernel product between the new data and only a few data points of the training set near the classification boundary. These data points are the support vectors.


## Traditional Formulation

ref Bishop



### Binary Classifier

### Multiclass SVM

Although the application of SVMs to multiclass classification problems remains an open issue, in practice the one-versus-the-rest approach is the most widely used in spite of its ad-hoc formula- tion and its practical limitations.

## Prof. Lee's Formulation by the 3 Steps of ML

